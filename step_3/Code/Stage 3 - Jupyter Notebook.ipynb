{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This IPython notebook explains a basic workflow two tables using py_entitymatching. The goal is to come up with a workflow to match books from Goodreads and Amazon. Specifically, we want to maximize F1. The datasets contain information about the books.\n",
    "\n",
    "First, we need to import py_entitymatching package and other libraries as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.5.2 (default, Sep 14 2017, 22:51:06) \n",
      "[GCC 5.4.0 20160609]\n",
      "pandas version: 0.20.3\n",
      "magellan version: 0.3.0\n"
     ]
    }
   ],
   "source": [
    "# Display the versions\n",
    "print('python version: ' + sys.version )\n",
    "print('pandas version: ' + pd.__version__ )\n",
    "print('magellan version: ' + em.__version__ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching two tables typically consists of the following three steps:\n",
    "\n",
    "1. Reading the input tables\n",
    "\n",
    "2. Blocking the input tables to get a candidate set\n",
    "\n",
    "3. Matching the tuple pairs in the candidate set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "source1 = 'source1_cleaned.csv'\n",
    "source2 = 'source2_cleaned.csv'\n",
    "\n",
    "# Read the data\n",
    "A = em.read_csv_metadata(source1)\n",
    "B = em.read_csv_metadata(source2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the metadata\n",
    "em.set_key(A, 'ID')\n",
    "em.set_key(B, 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tuples in A: 3387\n",
      "Number of tuples in B: 3001\n",
      "Number of tuples in A X B (i.e the cartesian product): 10164387\n"
     ]
    }
   ],
   "source": [
    "print('Number of tuples in A: ' + str(len(A)))\n",
    "print('Number of tuples in B: ' + str(len(B)))\n",
    "print('Number of tuples in A X B (i.e the cartesian product): ' + str(len(A)*len(B)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Publishing_Date</th>\n",
       "      <th>Format</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Age of Myth: Book One of The Legends of the First Empire</td>\n",
       "      <td>Michael J. Sullivan</td>\n",
       "      <td>Del Rey</td>\n",
       "      <td>2017-1-31</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>464.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Rise of the Dragons (Kings and Sorcerers--Book 1)</td>\n",
       "      <td>Morgan Rice</td>\n",
       "      <td>Morgan Rice</td>\n",
       "      <td>2017-8-4</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>217.0</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                                      Name  \\\n",
       "0   0  Age of Myth: Book One of The Legends of the First Empire   \n",
       "1   1         Rise of the Dragons (Kings and Sorcerers--Book 1)   \n",
       "\n",
       "                Author    Publisher Publishing_Date     Format  Pages  Rating  \n",
       "0  Michael J. Sullivan      Del Rey       2017-1-31  Paperback  464.0     4.5  \n",
       "1          Morgan Rice  Morgan Rice        2017-8-4  Hardcover  217.0     4.1  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Publishing_Date</th>\n",
       "      <th>Format</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Brides of Fantasy</td>\n",
       "      <td>Vanilla Orchid Books</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kindle Edition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Italian Secretary: A Further Adventure Of Sherlock Holmes</td>\n",
       "      <td>Caleb Carr</td>\n",
       "      <td>Sphere</td>\n",
       "      <td>2015-11-27</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>288.0</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                                           Name  \\\n",
       "0   0                                              Brides of Fantasy   \n",
       "1   1  The Italian Secretary: A Further Adventure Of Sherlock Holmes   \n",
       "\n",
       "                 Author Publisher Publishing_Date          Format  Pages  \\\n",
       "0  Vanilla Orchid Books       NaN             NaN  Kindle Edition    NaN   \n",
       "1            Caleb Carr    Sphere      2015-11-27       Paperback  288.0   \n",
       "\n",
       "   Rating  \n",
       "0    0.00  \n",
       "1    3.19  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ID', 'ID')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the keys of the input tables\n",
    "em.get_key(A), em.get_key(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will proceed without downsampling the datasets and use the entire dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block tables to get candidate set\n",
    "Before we do the matching, we would like to remove the obviously non-matching tuple pairs from the input tables. This would reduce the number of tuple pairs considered for matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule Based Blocker\n",
    "We first get the tokenizers and the similarity functions and then get the attribute correspondence for the two tables. \n",
    "\n",
    "We then define the following rules:\n",
    "1. For a tuple pair, if the Levenshtein similarity for the **Name** attribute is less than 0.275, block them.\n",
    "2. For a tuple pair, if the Jaccard similarity for the **Author** attribute is less than 0.5, block them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_rule_1'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rule-Based blocker \n",
    "rb0 = em.RuleBasedBlocker()\n",
    "block_t = em.get_tokenizers_for_blocking()\n",
    "block_s = em.get_sim_funs_for_blocking()\n",
    "block_c = em.get_attr_corres(A, B)\n",
    "atypes_A = em.get_attr_types(A)\n",
    "atypes_B = em.get_attr_types(B)\n",
    "\n",
    "block_f = em.get_features(A, B, atypes_A, atypes_B, block_c, block_t, block_s)\n",
    "\n",
    "# add rule for book names : block tuples if Levenshtein Similarity is below 0.275\n",
    "rb0.add_rule(['Name_Name_lev_sim(ltuple, rtuple) < 0.275'], block_f)\n",
    "\n",
    "# add rule for authors : block tuples if Jaccard Similarity is below 0.5 in spaces delimited tokens\n",
    "rb0.add_rule(['Author_Author_jac_dlm_dc0_dlm_dc0(ltuple, rtuple) < 0.5'], block_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken : 6.324349999998958\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "C0 = rb0.block_tables(A, B,\n",
    "                    l_output_attrs=['ID', 'Name', 'Author', 'Publisher', 'Publishing_Date', 'Format', 'Pages', 'Rating'], \n",
    "                    r_output_attrs=['ID', 'Name', 'Author', 'Publisher', 'Publishing_Date', 'Format', 'Pages', 'Rating'],\n",
    "                     show_progress=False)\n",
    "\n",
    "end = timer()\n",
    "print(\"Time taken : \" + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2754\n"
     ]
    }
   ],
   "source": [
    "print(len(C0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ltable_ID</th>\n",
       "      <th>rtable_ID</th>\n",
       "      <th>ltable_Name</th>\n",
       "      <th>ltable_Author</th>\n",
       "      <th>ltable_Publisher</th>\n",
       "      <th>ltable_Publishing_Date</th>\n",
       "      <th>ltable_Format</th>\n",
       "      <th>ltable_Pages</th>\n",
       "      <th>ltable_Rating</th>\n",
       "      <th>rtable_Name</th>\n",
       "      <th>rtable_Author</th>\n",
       "      <th>rtable_Publisher</th>\n",
       "      <th>rtable_Publishing_Date</th>\n",
       "      <th>rtable_Format</th>\n",
       "      <th>rtable_Pages</th>\n",
       "      <th>rtable_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1281</td>\n",
       "      <td>22</td>\n",
       "      <td>The Magazine of Fantasy and Science Fiction, July 1969 (Volume 37, No. 1)</td>\n",
       "      <td>Fritz Leiber</td>\n",
       "      <td>Mercury Press</td>\n",
       "      <td>1969-0-0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gather, Darkness! (Nucleus Fantasy &amp; Science Fiction)</td>\n",
       "      <td>Fritz Leiber</td>\n",
       "      <td>Collier Books</td>\n",
       "      <td>1992-12-01</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>23</td>\n",
       "      <td>Beyond My Control: Forbidden Fantasies in an Uncensored Age</td>\n",
       "      <td>Nancy Friday</td>\n",
       "      <td>Sourcebooks</td>\n",
       "      <td>2009-4-1</td>\n",
       "      <td>Kindle</td>\n",
       "      <td>288.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Men in Love: Men's Sexual Fantasies: The Triumph of Love Over Rage</td>\n",
       "      <td>Nancy Friday</td>\n",
       "      <td>Dell</td>\n",
       "      <td>1982-12-15</td>\n",
       "      <td>Mass Market Paperback</td>\n",
       "      <td>544.0</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _id  ltable_ID  rtable_ID  \\\n",
       "14    0       1281         22   \n",
       "15    1        204         23   \n",
       "\n",
       "                                                                  ltable_Name  \\\n",
       "14  The Magazine of Fantasy and Science Fiction, July 1969 (Volume 37, No. 1)   \n",
       "15                Beyond My Control: Forbidden Fantasies in an Uncensored Age   \n",
       "\n",
       "   ltable_Author ltable_Publisher ltable_Publishing_Date ltable_Format  \\\n",
       "14  Fritz Leiber    Mercury Press               1969-0-0     Hardcover   \n",
       "15  Nancy Friday      Sourcebooks               2009-4-1        Kindle   \n",
       "\n",
       "    ltable_Pages  ltable_Rating  \\\n",
       "14           NaN            NaN   \n",
       "15         288.0            3.2   \n",
       "\n",
       "                                                           rtable_Name  \\\n",
       "14               Gather, Darkness! (Nucleus Fantasy & Science Fiction)   \n",
       "15  Men in Love: Men's Sexual Fantasies: The Triumph of Love Over Rage   \n",
       "\n",
       "   rtable_Author rtable_Publisher rtable_Publishing_Date  \\\n",
       "14  Fritz Leiber    Collier Books             1992-12-01   \n",
       "15  Nancy Friday             Dell             1982-12-15   \n",
       "\n",
       "            rtable_Format  rtable_Pages  rtable_Rating  \n",
       "14              Paperback         240.0           3.64  \n",
       "15  Mass Market Paperback         544.0           3.70  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C0.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlap Blocker\n",
    "We now apply the overlap blocker to the candidate set obtained in the previous step. Since the entity we are dealing with is books, there are quite a few stopwords present in the book names, such as \"The\", \"Of\", \"And\" etc. Hence we will remove these stopwords by setting the <i>rem_stop_words</i> to _True_ and then perform overlap blocking with the size set to 1.\n",
    "\n",
    "We apply overlap blocking to the following attributes:\n",
    "1. Book Names\n",
    "2. Book Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken : 0.17012899999826914\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "# Overlap blocker\n",
    "overlapBlocker = em.OverlapBlocker()\n",
    "overlapBlocker.stop_words.append('of')\n",
    "C1 = overlapBlocker.block_candset(C0, 'Name', 'Name', word_level=True, overlap_size=1, allow_missing=True, show_progress=False, rem_stop_words=True)\n",
    "\n",
    "C1 = overlapBlocker.block_candset(C1, 'Author', 'Author', word_level=True, overlap_size=1, allow_missing=True, show_progress=False, rem_stop_words=True)\n",
    "\n",
    "end = timer()\n",
    "print(\"Time taken : \" + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092\n"
     ]
    }
   ],
   "source": [
    "print(len(C1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ltable_ID</th>\n",
       "      <th>rtable_ID</th>\n",
       "      <th>ltable_Name</th>\n",
       "      <th>ltable_Author</th>\n",
       "      <th>ltable_Publisher</th>\n",
       "      <th>ltable_Publishing_Date</th>\n",
       "      <th>ltable_Format</th>\n",
       "      <th>ltable_Pages</th>\n",
       "      <th>ltable_Rating</th>\n",
       "      <th>rtable_Name</th>\n",
       "      <th>rtable_Author</th>\n",
       "      <th>rtable_Publisher</th>\n",
       "      <th>rtable_Publishing_Date</th>\n",
       "      <th>rtable_Format</th>\n",
       "      <th>rtable_Pages</th>\n",
       "      <th>rtable_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1281</td>\n",
       "      <td>22</td>\n",
       "      <td>The Magazine of Fantasy and Science Fiction, July 1969 (Volume 37, No. 1)</td>\n",
       "      <td>Fritz Leiber</td>\n",
       "      <td>Mercury Press</td>\n",
       "      <td>1969-0-0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gather, Darkness! (Nucleus Fantasy &amp; Science Fiction)</td>\n",
       "      <td>Fritz Leiber</td>\n",
       "      <td>Collier Books</td>\n",
       "      <td>1992-12-01</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>23</td>\n",
       "      <td>Beyond My Control: Forbidden Fantasies in an Uncensored Age</td>\n",
       "      <td>Nancy Friday</td>\n",
       "      <td>Sourcebooks</td>\n",
       "      <td>2009-4-1</td>\n",
       "      <td>Kindle</td>\n",
       "      <td>288.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Men in Love: Men's Sexual Fantasies: The Triumph of Love Over Rage</td>\n",
       "      <td>Nancy Friday</td>\n",
       "      <td>Dell</td>\n",
       "      <td>1982-12-15</td>\n",
       "      <td>Mass Market Paperback</td>\n",
       "      <td>544.0</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _id  ltable_ID  rtable_ID  \\\n",
       "14    0       1281         22   \n",
       "15    1        204         23   \n",
       "\n",
       "                                                                  ltable_Name  \\\n",
       "14  The Magazine of Fantasy and Science Fiction, July 1969 (Volume 37, No. 1)   \n",
       "15                Beyond My Control: Forbidden Fantasies in an Uncensored Age   \n",
       "\n",
       "   ltable_Author ltable_Publisher ltable_Publishing_Date ltable_Format  \\\n",
       "14  Fritz Leiber    Mercury Press               1969-0-0     Hardcover   \n",
       "15  Nancy Friday      Sourcebooks               2009-4-1        Kindle   \n",
       "\n",
       "    ltable_Pages  ltable_Rating  \\\n",
       "14           NaN            NaN   \n",
       "15         288.0            3.2   \n",
       "\n",
       "                                                           rtable_Name  \\\n",
       "14               Gather, Darkness! (Nucleus Fantasy & Science Fiction)   \n",
       "15  Men in Love: Men's Sexual Fantasies: The Triumph of Love Over Rage   \n",
       "\n",
       "   rtable_Author rtable_Publisher rtable_Publishing_Date  \\\n",
       "14  Fritz Leiber    Collier Books             1992-12-01   \n",
       "15  Nancy Friday             Dell             1982-12-15   \n",
       "\n",
       "            rtable_Format  rtable_Pages  rtable_Rating  \n",
       "14              Paperback         240.0           3.64  \n",
       "15  Mass Market Paperback         544.0           3.70  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug blocker output\n",
    "The number of tuple pairs considered for matching is reduced to 1092 (from 10164387), but we would want to make sure that the blocker did not drop any potential matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug blocker output\n",
    "dbg = em.debug_blocker(C1, A, B, output_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ltable_ID</th>\n",
       "      <th>rtable_ID</th>\n",
       "      <th>ltable_Name</th>\n",
       "      <th>ltable_Author</th>\n",
       "      <th>ltable_Publisher</th>\n",
       "      <th>ltable_Publishing_Date</th>\n",
       "      <th>ltable_Format</th>\n",
       "      <th>rtable_Name</th>\n",
       "      <th>rtable_Author</th>\n",
       "      <th>rtable_Publisher</th>\n",
       "      <th>rtable_Publishing_Date</th>\n",
       "      <th>rtable_Format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>457</td>\n",
       "      <td>285</td>\n",
       "      <td>Final Fantasy X-X2 HD Remaster Official Strategy Guide</td>\n",
       "      <td>BradyGames</td>\n",
       "      <td>BRADY GAMES</td>\n",
       "      <td>2014-3-18</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>Final Fantasy VII: Official Strategy Guide</td>\n",
       "      <td>David Cassady</td>\n",
       "      <td>Bradygames</td>\n",
       "      <td>1998-06-12</td>\n",
       "      <td>Paperback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>457</td>\n",
       "      <td>2719</td>\n",
       "      <td>Final Fantasy X-X2 HD Remaster Official Strategy Guide</td>\n",
       "      <td>BradyGames</td>\n",
       "      <td>BRADY GAMES</td>\n",
       "      <td>2014-3-18</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>FINAL FANTASY X Official Strategy Guide</td>\n",
       "      <td>Dan Birlew</td>\n",
       "      <td>BradyGames</td>\n",
       "      <td>2001-12-17</td>\n",
       "      <td>Paperback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>457</td>\n",
       "      <td>2378</td>\n",
       "      <td>Final Fantasy X-X2 HD Remaster Official Strategy Guide</td>\n",
       "      <td>BradyGames</td>\n",
       "      <td>BRADY GAMES</td>\n",
       "      <td>2014-3-18</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>Final Fantasy VIII Official Strategy Guide</td>\n",
       "      <td>David Cassady</td>\n",
       "      <td>BradyGames</td>\n",
       "      <td>1999-08-31</td>\n",
       "      <td>Paperback</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  ltable_ID  rtable_ID  \\\n",
       "0    0        457        285   \n",
       "1    1        457       2719   \n",
       "2    2        457       2378   \n",
       "\n",
       "                                              ltable_Name ltable_Author  \\\n",
       "0  Final Fantasy X-X2 HD Remaster Official Strategy Guide    BradyGames   \n",
       "1  Final Fantasy X-X2 HD Remaster Official Strategy Guide    BradyGames   \n",
       "2  Final Fantasy X-X2 HD Remaster Official Strategy Guide    BradyGames   \n",
       "\n",
       "  ltable_Publisher ltable_Publishing_Date ltable_Format  \\\n",
       "0      BRADY GAMES              2014-3-18     Hardcover   \n",
       "1      BRADY GAMES              2014-3-18     Hardcover   \n",
       "2      BRADY GAMES              2014-3-18     Hardcover   \n",
       "\n",
       "                                  rtable_Name  rtable_Author rtable_Publisher  \\\n",
       "0  Final Fantasy VII: Official Strategy Guide  David Cassady       Bradygames   \n",
       "1     FINAL FANTASY X Official Strategy Guide     Dan Birlew       BradyGames   \n",
       "2  Final Fantasy VIII Official Strategy Guide  David Cassady       BradyGames   \n",
       "\n",
       "  rtable_Publishing_Date rtable_Format  \n",
       "0             1998-06-12     Paperback  \n",
       "1             2001-12-17     Paperback  \n",
       "2             1999-08-31     Paperback  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbg.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that we already have some matches. Since the number of matches has dropped to just 1092 from 10164387, we decided to stop debugging the blocking step and proceed with training a matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the tuples which survived the blocking step\n",
    "C1.to_csv(\"TuplesAfterBlocking.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling the candidate set\n",
    "We labeled the tuples from the previous step as a match or not. 1 indicates a match and 0 indicates a non match. We did not use the <i>label_table</i> function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sample 500 tuple pairs for labeling, from the 1092 obtained after blocking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 500 tuples for labeling\n",
    "S = em.sample_table(C1, 500)\n",
    "\n",
    "# Save this for labeling\n",
    "S.to_csv('TuplesForLabeling.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling 1092 tuples took roughly 45 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "# Load the golden data\n",
    "S = em.read_csv_metadata('TuplesForLabeling_cleaned.csv', key='_id', ltable=A, rtable=B, \n",
    "                         fk_ltable='ltable_ID', fk_rtable='rtable_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples from the golden data; The last column **match** indicates the labels we've added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ltable_ID</th>\n",
       "      <th>rtable_ID</th>\n",
       "      <th>ltable_Name</th>\n",
       "      <th>ltable_Author</th>\n",
       "      <th>ltable_Publisher</th>\n",
       "      <th>ltable_Format</th>\n",
       "      <th>ltable_Pages</th>\n",
       "      <th>ltable_Rating</th>\n",
       "      <th>rtable_Name</th>\n",
       "      <th>rtable_Author</th>\n",
       "      <th>rtable_Publisher</th>\n",
       "      <th>rtable_Format</th>\n",
       "      <th>rtable_Pages</th>\n",
       "      <th>rtable_Rating</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>478</td>\n",
       "      <td>The Fantasy Baseball Black Book 2018 (Fantasy Black Book)</td>\n",
       "      <td>Joe Pisapia</td>\n",
       "      <td>Independently published</td>\n",
       "      <td>Kindle</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>The Fantasy Baseball Black Book 2017 Edition (Fantasy Black Book 10)</td>\n",
       "      <td>Joe Pisapia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kindle Edition</td>\n",
       "      <td>182.0</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>378</td>\n",
       "      <td>13</td>\n",
       "      <td>2888</td>\n",
       "      <td>Grimgar of Fantasy and Ash (Light Novel) Vol. 1</td>\n",
       "      <td>Ao Jyumonji</td>\n",
       "      <td>Seven Seas</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>280.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Grimgar of Fantasy and Ash, Vol. 1</td>\n",
       "      <td>Ao Jyumonji</td>\n",
       "      <td>Yen Press</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>224.0</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>309</td>\n",
       "      <td>13</td>\n",
       "      <td>2615</td>\n",
       "      <td>Grimgar of Fantasy and Ash (Light Novel) Vol. 1</td>\n",
       "      <td>Ao Jyumonji</td>\n",
       "      <td>Seven Seas</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>280.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Grimgar of Fantasy and Ash: Volume 3</td>\n",
       "      <td>Ao Jyumonji</td>\n",
       "      <td>J-Novel Club</td>\n",
       "      <td>Kindle Edition</td>\n",
       "      <td>280.0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  ltable_ID  rtable_ID  \\\n",
       "0   51          5        478   \n",
       "1  378         13       2888   \n",
       "2  309         13       2615   \n",
       "\n",
       "                                                 ltable_Name ltable_Author  \\\n",
       "0  The Fantasy Baseball Black Book 2018 (Fantasy Black Book)   Joe Pisapia   \n",
       "1            Grimgar of Fantasy and Ash (Light Novel) Vol. 1   Ao Jyumonji   \n",
       "2            Grimgar of Fantasy and Ash (Light Novel) Vol. 1   Ao Jyumonji   \n",
       "\n",
       "          ltable_Publisher ltable_Format  ltable_Pages  ltable_Rating  \\\n",
       "0  Independently published        Kindle         157.0            4.6   \n",
       "1               Seven Seas     Paperback         280.0            4.3   \n",
       "2               Seven Seas     Paperback         280.0            4.3   \n",
       "\n",
       "                                                            rtable_Name  \\\n",
       "0  The Fantasy Baseball Black Book 2017 Edition (Fantasy Black Book 10)   \n",
       "1                                    Grimgar of Fantasy and Ash, Vol. 1   \n",
       "2                                  Grimgar of Fantasy and Ash: Volume 3   \n",
       "\n",
       "  rtable_Author rtable_Publisher   rtable_Format  rtable_Pages  rtable_Rating  \\\n",
       "0   Joe Pisapia              NaN  Kindle Edition         182.0           3.88   \n",
       "1   Ao Jyumonji        Yen Press       Paperback         224.0           3.43   \n",
       "2   Ao Jyumonji     J-Novel Club  Kindle Edition         280.0           4.26   \n",
       "\n",
       "   match  \n",
       "0      0  \n",
       "1      1  \n",
       "2      0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the labeled data into development and evaluation set\n",
    "In this step, we split the labeled data into two sets: development (I) and evaluation (J). Specifically, the development set is used to come up with the best learning-based matcher and the evaluation set used to evaluate the selected matcher on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split S into development set (I) and evaluation set (J)\n",
    "IJ = em.split_train_test(S, train_proportion=0.7, random_state=42)\n",
    "I = IJ['train']\n",
    "J = IJ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 150)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(I), len(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Set I and Set J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "I.to_csv(\"SetI.csv\", encoding='utf-8', index=False)\n",
    "J.to_csv(\"SetJ.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best learning-based matcher\n",
    "Selecting the best learning-based matcher typically involves the following steps:\n",
    "\n",
    "1. Creating a set of learning-based matchers\n",
    "2. Creating features\n",
    "3. Converting the development set into feature vectors\n",
    "4. Selecting the best learning-based matcher using k-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a set of learning-based matchers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we tuned the hyperparameters a bit so that they are more relavent to our scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of ML-matchers\n",
    "dt = em.DTMatcher(name='DecisionTree', random_state=0, criterion='gini', class_weight='balanced')\n",
    "svm = em.SVMMatcher(name='SVM', kernel='linear', random_state=0)\n",
    "rf = em.RFMatcher(name='RF', n_estimators=50, criterion='gini', class_weight='balanced', random_state=0)\n",
    "lg = em.LogRegMatcher(name='LogReg', penalty='l2', class_weight='balanced', random_state=0)\n",
    "ln = em.LinRegMatcher(name='LinReg')\n",
    "nb = em.NBMatcher(name='NaiveBayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating features\n",
    "Here we use the automatically generated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features\n",
    "feature_table = em.get_features_for_matching(A, B, validate_inferred_attr_types=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           ID_ID_exm\n",
       "1                                           ID_ID_anm\n",
       "2                                      ID_ID_lev_dist\n",
       "3                                       ID_ID_lev_sim\n",
       "4                           Name_Name_jac_qgm_3_qgm_3\n",
       "5                       Name_Name_cos_dlm_dc0_dlm_dc0\n",
       "6                                       Name_Name_mel\n",
       "7                                  Name_Name_lev_dist\n",
       "8                                   Name_Name_lev_sim\n",
       "9                       Author_Author_jac_qgm_3_qgm_3\n",
       "10                  Author_Author_cos_dlm_dc0_dlm_dc0\n",
       "11                  Author_Author_jac_dlm_dc0_dlm_dc0\n",
       "12                                  Author_Author_mel\n",
       "13                             Author_Author_lev_dist\n",
       "14                              Author_Author_lev_sim\n",
       "15                                  Author_Author_nmw\n",
       "16                                   Author_Author_sw\n",
       "17                Publisher_Publisher_jac_qgm_3_qgm_3\n",
       "18            Publisher_Publisher_cos_dlm_dc0_dlm_dc0\n",
       "19            Publisher_Publisher_jac_dlm_dc0_dlm_dc0\n",
       "20                            Publisher_Publisher_mel\n",
       "21                       Publisher_Publisher_lev_dist\n",
       "22                        Publisher_Publisher_lev_sim\n",
       "23                            Publisher_Publisher_nmw\n",
       "24                             Publisher_Publisher_sw\n",
       "25           Publishing_Date_Publishing_Date_lev_dist\n",
       "26            Publishing_Date_Publishing_Date_lev_sim\n",
       "27                Publishing_Date_Publishing_Date_jar\n",
       "28                Publishing_Date_Publishing_Date_jwn\n",
       "29                Publishing_Date_Publishing_Date_exm\n",
       "30    Publishing_Date_Publishing_Date_jac_qgm_3_qgm_3\n",
       "31                                    Pages_Pages_exm\n",
       "32                                    Pages_Pages_anm\n",
       "33                               Pages_Pages_lev_dist\n",
       "34                                Pages_Pages_lev_sim\n",
       "35                                  Rating_Rating_exm\n",
       "36                                  Rating_Rating_anm\n",
       "37                             Rating_Rating_lev_dist\n",
       "38                              Rating_Rating_lev_sim\n",
       "Name: feature_name, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the names of the features generated\n",
    "feature_table['feature_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove a few features from the generated set of features. The reasoning is as follows:\n",
    "\n",
    "Consider the **Publisher** attribute. While labeling the true matches, we marked a tuple pair as a true match even if the publishers did not match. The same book is usually sold in different countries under different publishers and hence though the publishers might differ, the book still refers to the same real world object. Hence we do not consider the **Publisher** attribute as a feature, as they might differ for a match. The same reasoning is extended to **Pages** and **Rating** attributes as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop publishing date, rating related features\n",
    "feature_table = feature_table.drop([0,1,2,3,17,18,19,20,21,22,23,24,25,30,34,35,36,37,38])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the development set to feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the I into a set of feature vectors using F\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=feature_table, \n",
    "                            attrs_after='match',\n",
    "                            show_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                                          0\n",
       "ltable_ID                                    0\n",
       "rtable_ID                                    0\n",
       "Name_Name_jac_qgm_3_qgm_3                    0\n",
       "Name_Name_cos_dlm_dc0_dlm_dc0                0\n",
       "Name_Name_mel                                0\n",
       "Name_Name_lev_dist                           0\n",
       "Name_Name_lev_sim                            0\n",
       "Author_Author_jac_qgm_3_qgm_3              234\n",
       "Author_Author_cos_dlm_dc0_dlm_dc0          234\n",
       "Author_Author_jac_dlm_dc0_dlm_dc0          234\n",
       "Author_Author_mel                          234\n",
       "Author_Author_lev_dist                     234\n",
       "Author_Author_lev_sim                      234\n",
       "Author_Author_nmw                          234\n",
       "Author_Author_sw                           234\n",
       "Publishing_Date_Publishing_Date_lev_sim     36\n",
       "Publishing_Date_Publishing_Date_jar         36\n",
       "Publishing_Date_Publishing_Date_jwn         36\n",
       "Publishing_Date_Publishing_Date_exm         36\n",
       "Pages_Pages_exm                             49\n",
       "Pages_Pages_anm                             49\n",
       "Pages_Pages_lev_dist                        49\n",
       "match                                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing values with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = em.impute_table(H, \n",
    "                exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'],\n",
    "                strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the best matcher using cross-validation\n",
    "Now, we select the best matcher using k-fold cross-validation. We use five fold cross validation and use 'precision' and 'recall' metric to select the best matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.62093399999867\n"
     ]
    }
   ],
   "source": [
    "# Select the best ML matcher using CV\n",
    "start = timer()\n",
    "result = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'],\n",
    "        k=5,\n",
    "        target_attr='match', metric_to_select_matcher='f1', random_state=42)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Matcher  Average precision  Average recall  Average f1\n",
      "0  DecisionTree           0.592857        0.590476    0.564267\n",
      "1            RF           0.966667        0.612381    0.707459\n",
      "2           SVM           0.852381        0.590476    0.637121\n",
      "3        LinReg           0.893333        0.566667    0.675556\n",
      "4        LogReg           0.595311        0.886667    0.690131\n",
      "5    NaiveBayes           0.609286        0.824762    0.691784\n"
     ]
    }
   ],
   "source": [
    "print(result['cv_stats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Name  \\\n",
      "0  DecisionTree   \n",
      "1            RF   \n",
      "2           SVM   \n",
      "3        LinReg   \n",
      "4        LogReg   \n",
      "5    NaiveBayes   \n",
      "\n",
      "                                                                            Matcher  \\\n",
      "0          <py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x7f9d7c444a58>   \n",
      "1          <py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x7f9d7c444a20>   \n",
      "2        <py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x7f9d7c444978>   \n",
      "3  <py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x7f9d7bd83d30>   \n",
      "4  <py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x7f9d7c4444e0>   \n",
      "5          <py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x7f9d7bd83550>   \n",
      "\n",
      "   Num folds    Fold 1    Fold 2    Fold 3    Fold 4    Fold 5  Mean score  \n",
      "0          5  0.666667  0.714286  0.625000  0.615385  0.200000    0.564267  \n",
      "1          5  0.909091  0.833333  0.461538  0.833333  0.500000    0.707459  \n",
      "2          5  0.833333  0.714286  0.625000  0.727273  0.285714    0.637121  \n",
      "3          5  1.000000  0.600000  0.666667  0.666667  0.444444    0.675556  \n",
      "4          5  0.526316  0.823529  0.631579  0.700000  0.769231    0.690131  \n",
      "5          5  0.769231  0.736842  0.631579  0.705882  0.615385    0.691784  \n"
     ]
    }
   ],
   "source": [
    "print(result['drill_down_cv_stats']['f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As seen here, the random forest classifier has a precision of over 90% (96.66%) and has a recall of 61.23%. It also has the highest F1 score. Hence we do not debug further and proceed to use the random forest classifier on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the matching output\n",
    "Evaluating the matching outputs for the evaluation set typically involves the following four steps:\n",
    "\n",
    "1. Converting the evaluation set to feature vectors\n",
    "2. Training matcher using the feature vectors extracted from the development set\n",
    "3. Predicting the evaluation set using the trained matcher\n",
    "4. Evaluating the predicted matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the evaluation set to feature vectors\n",
    "As before, we convert to the feature vectors (using the feature table and the evaluation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "# Convert J into a set of feature vectors using F\n",
    "L = em.extract_feature_vecs(J, feature_table=feature_table,\n",
    "                            attrs_after='match', show_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute the missing values in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "L = em.impute_table(L, \n",
    "                exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'],\n",
    "                strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the selected matcher\n",
    "Now, we train the matcher using all of the feature vectors from the development set. Here, we use random forest as the selected matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using feature vectors from I \n",
    "rf.fit(table=L, \n",
    "       exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'], \n",
    "       target_attr='match')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the matches\n",
    "Next, we predict the matches for the evaluation set (using the feature vectors extracted from it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on L \n",
    "predictions = rf.predict(table=L, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'], \n",
    "              append=True, target_attr='predicted', inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the predictions\n",
    "Finally, we evaluate the accuracy of predicted outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 100.0% (12/12)\n",
      "Recall : 100.0% (12/12)\n",
      "F1 : 100.0%\n",
      "False positives : 0 (out of 12 positive predictions)\n",
      "False negatives : 0 (out of 138 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'match', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on all learning methods\n",
    "Here we see how the other 5 learning methods perform on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 100.0% (12/12)\n",
      "Recall : 100.0% (12/12)\n",
      "F1 : 100.0%\n",
      "False positives : 0 (out of 12 positive predictions)\n",
      "False negatives : 0 (out of 138 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "dt.fit(table=L, \n",
    "       exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'], \n",
    "       target_attr='match')\n",
    "\n",
    "# Predict on L \n",
    "predictions = dt.predict(table=L, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'match', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 88.89% (8/9)\n",
      "Recall : 66.67% (8/12)\n",
      "F1 : 76.19%\n",
      "False positives : 1 (out of 9 positive predictions)\n",
      "False negatives : 4 (out of 141 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "svm.fit(table=L, \n",
    "       exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'], \n",
    "       target_attr='match')\n",
    "\n",
    "# Predict on L \n",
    "predictions = svm.predict(table=L, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'match', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logisitic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 57.89% (11/19)\n",
      "Recall : 91.67% (11/12)\n",
      "F1 : 70.97%\n",
      "False positives : 8 (out of 19 positive predictions)\n",
      "False negatives : 1 (out of 131 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "lg.fit(table=L, \n",
    "       exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'], \n",
    "       target_attr='match')\n",
    "\n",
    "# Predict on L \n",
    "predictions = lg.predict(table=L, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'match', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 90.0% (9/10)\n",
      "Recall : 75.0% (9/12)\n",
      "F1 : 81.82%\n",
      "False positives : 1 (out of 10 positive predictions)\n",
      "False negatives : 3 (out of 140 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "ln.fit(table=L, \n",
    "       exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'], \n",
    "       target_attr='match')\n",
    "\n",
    "# Predict on L \n",
    "predictions = ln.predict(table=L, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'match', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 50.0% (9/18)\n",
      "Recall : 75.0% (9/12)\n",
      "F1 : 60.0%\n",
      "False positives : 9 (out of 18 positive predictions)\n",
      "False negatives : 3 (out of 132 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "nb.fit(table=L, \n",
    "       exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'], \n",
    "       target_attr='match')\n",
    "\n",
    "# Predict on L \n",
    "predictions = nb.predict(table=L, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'match', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
