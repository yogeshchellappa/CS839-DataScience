{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "source1 = 'source1_cleaned.csv'\n",
    "source2 = 'source2_cleaned.csv'\n",
    "\n",
    "# Read the data\n",
    "A = em.read_csv_metadata(source1)\n",
    "B = em.read_csv_metadata(source2)\n",
    "\n",
    "# Set the metadata\n",
    "em.set_key(A, 'ID')\n",
    "em.set_key(B, 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "# Load the golden data\n",
    "S = em.read_csv_metadata('TuplesForLabeling_cleaned.csv', key='_id', ltable=A, rtable=B, \n",
    "                         fk_ltable='ltable_ID', fk_rtable='rtable_ID')\n",
    "\n",
    "# Split S into development set (I) and evaluation set (J)\n",
    "IJ = em.split_train_test(S, train_proportion=0.7, random_state=42)\n",
    "I = IJ['train']\n",
    "J = IJ['test']\n",
    "\n",
    "# Create a set of ML-matchers\n",
    "dt = em.DTMatcher(name='DecisionTree', random_state=0, criterion='gini', class_weight='balanced')\n",
    "svm = em.SVMMatcher(name='SVM', kernel='linear', random_state=0)\n",
    "rf = em.RFMatcher(name='RF', n_estimators=50, criterion='gini', class_weight='balanced', random_state=0)\n",
    "lg = em.LogRegMatcher(name='LogReg', penalty='l2', class_weight='balanced', random_state=0)\n",
    "ln = em.LinRegMatcher(name='LinReg')\n",
    "nb = em.NBMatcher(name='NaiveBayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features\n",
    "feature_table = em.get_features_for_matching(A, B, validate_inferred_attr_types=False)\n",
    "\n",
    "# Drop unnecesary features. Here, we performed multiple iterations and tried out different combinations\n",
    "feature_table = feature_table.drop([0,1,2,3,17,18,19,20,21,22,23,24,25,30,34,35,36,37,38])\n",
    "\n",
    "# Convert the I into a set of feature vectors using F\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=feature_table, \n",
    "                            attrs_after='match',\n",
    "                            show_progress=False)\n",
    "\n",
    "H = em.impute_table(H, \n",
    "                exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'],\n",
    "                strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Matcher  Average precision  Average recall  Average f1\n",
      "0  DecisionTree           0.592857        0.590476    0.564267\n",
      "1            RF           0.966667        0.612381    0.707459\n",
      "2           SVM           0.852381        0.590476    0.637121\n",
      "3        LinReg           0.893333        0.566667    0.675556\n",
      "4        LogReg           0.595311        0.886667    0.690131\n",
      "5    NaiveBayes           0.609286        0.824762    0.691784\n",
      "           Name  \\\n",
      "0  DecisionTree   \n",
      "1            RF   \n",
      "2           SVM   \n",
      "3        LinReg   \n",
      "4        LogReg   \n",
      "5    NaiveBayes   \n",
      "\n",
      "                                                                         Matcher  \\\n",
      "0          <py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x10f4e9cf8>   \n",
      "1          <py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x10f4e9978>   \n",
      "2        <py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x10f4e9898>   \n",
      "3  <py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x10f4e9e48>   \n",
      "4  <py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x10f4e9c88>   \n",
      "5          <py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x10f4e9828>   \n",
      "\n",
      "   Num folds    Fold 1    Fold 2    Fold 3    Fold 4    Fold 5  Mean score  \n",
      "0          5  0.666667  0.714286  0.625000  0.615385  0.200000    0.564267  \n",
      "1          5  0.909091  0.833333  0.461538  0.833333  0.500000    0.707459  \n",
      "2          5  0.833333  0.714286  0.625000  0.727273  0.285714    0.637121  \n",
      "3          5  1.000000  0.600000  0.666667  0.666667  0.444444    0.675556  \n",
      "4          5  0.526316  0.823529  0.631579  0.700000  0.769231    0.690131  \n",
      "5          5  0.769231  0.736842  0.631579  0.705882  0.615385    0.691784  \n"
     ]
    }
   ],
   "source": [
    "# Create a set of ML-matchers\n",
    "dt = em.DTMatcher(name='DecisionTree', random_state=0, criterion='gini', class_weight='balanced')\n",
    "svm = em.SVMMatcher(name='SVM', kernel='linear', random_state=0)\n",
    "rf = em.RFMatcher(name='RF', n_estimators=50, criterion='gini', class_weight='balanced', random_state=0)\n",
    "lg = em.LogRegMatcher(name='LogReg', penalty='l2', class_weight='balanced', random_state=0)\n",
    "ln = em.LinRegMatcher(name='LinReg')\n",
    "nb = em.NBMatcher(name='NaiveBayes')\n",
    "\n",
    "result = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'],\n",
    "        k=5,\n",
    "        target_attr='match', metric_to_select_matcher='f1', random_state=42)\n",
    "\n",
    "print(result['cv_stats'])\n",
    "print(result['drill_down_cv_stats']['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 100.0% (35/35)\n",
      "Recall : 100.0% (35/35)\n",
      "F1 : 100.0%\n",
      "False positives : 0 (out of 35 positive predictions)\n",
      "False negatives : 0 (out of 315 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Debugging Random forest\n",
    "# Fit the random forest to the feature vectors\n",
    "rf.fit(table=H, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'], target_attr='match')\n",
    "\n",
    "# Use the SVM matcher to predict if tuple pairs match\n",
    "predictions = rf.predict(table=H, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'], target_attr='predicted_labels', \n",
    "           append=True, inplace=False)\n",
    "\n",
    "eval_result = em.eval_matches(predictions, 'match', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [_id, ltable_ID, rtable_ID, Name_Name_jac_qgm_3_qgm_3, Name_Name_cos_dlm_dc0_dlm_dc0, Name_Name_mel, Name_Name_lev_dist, Name_Name_lev_sim, Author_Author_jac_qgm_3_qgm_3, Author_Author_cos_dlm_dc0_dlm_dc0, Author_Author_jac_dlm_dc0_dlm_dc0, Author_Author_mel, Author_Author_lev_dist, Author_Author_lev_sim, Author_Author_nmw, Author_Author_sw, Publishing_Date_Publishing_Date_lev_sim, Publishing_Date_Publishing_Date_jar, Publishing_Date_Publishing_Date_jwn, Publishing_Date_Publishing_Date_exm, Pages_Pages_exm, Pages_Pages_anm, Pages_Pages_lev_dist, match, predicted_labels]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check the bad predictions (if any), split train set and debug using GUI\n",
    "print (predictions[predictions['match'] != predictions['predicted_labels']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 100.0% (35/35)\n",
      "Recall : 100.0% (35/35)\n",
      "F1 : 100.0%\n",
      "False positives : 0 (out of 35 positive predictions)\n",
      "False negatives : 0 (out of 315 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Try out trigger rules \n",
    "# Triggers\n",
    "# Use the constructor to create a trigger\n",
    "mt = em.MatchTrigger()\n",
    "mt.add_cond_rule(['Name_Name_cos_dlm_dc0_dlm_dc0(ltuple, rtuple) >= 0.9', 'Author_Author_cos_dlm_dc0_dlm_dc0(ltuple, rtuple) >= 0.9'], feature_table)\n",
    "mt.add_cond_status(True)\n",
    "mt.add_action(1)\n",
    "\n",
    "preds = mt.execute(input_table=predictions, label_column='predicted_labels', inplace=True)\n",
    "predictions.head()\n",
    "eval_result = em.eval_matches(predictions, 'match', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "\n",
    "# Debug RF matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'match'],\n",
    "        target_attr='match')\n",
    "\n",
    "# Repeat the above steps multiple times to debug and get the best out of the matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
